{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a415449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading Excel file: [Errno 2] No such file or directory: '.xlsx'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/vl7v8b496h3fs87b4fnt9qcw0000gn/T/ipykernel_24250/341251463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    189\u001b[0m     }\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mbulk_download_projectID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pd/vl7v8b496h3fs87b4fnt9qcw0000gn/T/ipykernel_24250/341251463.py\u001b[0m in \u001b[0;36mbulk_download_projectID\u001b[0;34m(input_dict)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocument_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_type_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mSingleTypeBulkDownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pd/vl7v8b496h3fs87b4fnt9qcw0000gn/T/ipykernel_24250/341251463.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dict, document_type_raw)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_date'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the start date from the input dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the end date from the input dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import requests  # For HTTP requests\n",
    "import re  # For regular expressions\n",
    "import os  # For interacting with the operating system\n",
    "import time  # For time-related operations\n",
    "import json  # For handling JSON data\n",
    "import shutil  # For file operations like copy, move, delete, etc.\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from openpyxl import Workbook  # For creating and manipulating Excel workbooks\n",
    "\n",
    "\n",
    "\n",
    "# Mapping of document types to their corresponding names in the World Bank API\n",
    "FileNameConvertDict = {\n",
    "    'icrr': 'Implementation+Completion+Report+Review',\n",
    "    'icr': \"Implementation+Completion+and+Results+Report\",\n",
    "    'ppar': \"Project+Performance+Assessment+Report\",\n",
    "    'pad': 'Project+Appraisal+Document',\n",
    "    'scd': 'Systematic+Country+Diagnostic',\n",
    "    'isr': 'Implementation+Status+and+Results+Report',\n",
    "    'pd': 'Program+Document',\n",
    "    'esmp': 'Environmental+and+Social+Management+Plan',\n",
    "    'cas': 'Country+Assistance+Strategy+Document',\n",
    "    'cpf': 'Country+Partnership+Framework',\n",
    "    'cpe': 'IEG+Evaluation',\n",
    "    'cen': 'Country+Engagement+Note',\n",
    "    'cren': 'Country+Re-engagement+Note',\n",
    "    'isn': 'Interim+Strategy+Note',\n",
    "    'cpe': 'Country+Program+Evaluation',\n",
    "    'asa': 'Economic+%26+Sector+Work',\n",
    "    'clrr': 'CAS+Completion+Report+Review',\n",
    "    'pp': 'Project+Paper',\n",
    "}\n",
    "\n",
    "class SingleTypeBulkDownload(object):\n",
    "    \n",
    "    def __init__(self, input_dict, document_type_raw):\n",
    "        \"\"\"\n",
    "        Initialize SingleTypeBulkDownload instance.\n",
    "\n",
    "        Args:\n",
    "            input_dict (dict): A dictionary containing the input parameters.\n",
    "            document_type_raw (str): The raw document type.\n",
    "        \"\"\"\n",
    "        self.root_path = input_dict['root_path']  # Set the root path for the download\n",
    "        self.document_type_raw = document_type_raw  # Set the raw document type\n",
    "        self.output_path = os.path.join(self.root_path, f\"{self.document_type_raw}_folder\")  # Create the output path for the downloaded files\n",
    "        self.category_path = os.path.join(self.root_path, f\"{self.document_type_raw}_category_folder\")  # Create the category path for catalog files\n",
    "        # Create the necessary folders if they don't exist\n",
    "        for path in self.root_path, self.output_path, self.category_path:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "        self.start_date = input_dict.get('start_date')  # Get the start date from the input dictionary\n",
    "        self.end_date = input_dict.get('end_date')  # Get the end date from the input dictionary\n",
    "        self.document_type = FileNameConvertDict.get(self.document_type_raw)  # Get the converted document type\n",
    "        self.projid_list = input_dict.get('projid_list')  # Get the project ID list from the input dictionary\n",
    "        self.local_time = time.strftime(\"%m-%d-%Y\", time.localtime())  # Get the current local time\n",
    "        self.download_version = input_dict.get('download_version', 'txt')  # Get the download version from the input dictionary\n",
    "\n",
    "    def read_catalog_files(self):\n",
    "        \"\"\"\n",
    "        Read catalog files and yield the query file dictionary and file name.\n",
    "        \"\"\"\n",
    "        file_name_list = os.listdir(self.category_path)  # Get the list of file names in the category path directory\n",
    "        file_name_list = [file_name for file_name in file_name_list if file_name.startswith(self.document_type_raw) and file_name.endswith(\".txt\")]  # Filter file names based on document type and extension\n",
    "        for file_name in file_name_list:  # Iterate over the filtered file names\n",
    "            with open(os.path.join(self.category_path, file_name), 'r', encoding='utf-8', errors='ignore') as f:  # Open the file for reading\n",
    "                query_file_dict = json.loads(f.read()).get('documents')  # Parse the JSON content of the file into a dictionary\n",
    "                yield (query_file_dict, file_name)  # Yield the query file dictionary and file name as a tuple\n",
    "   \n",
    "     \n",
    "       \n",
    "    def generate_catalog_for_projects(self):\n",
    "        \"\"\"\n",
    "        Generate catalog files for the project-based method.\n",
    "        \"\"\"\n",
    "        failed_requests_count = 0  # Counter for failed requests\n",
    "        file_name_list = os.listdir(self.category_path)  # List of existing file names in the category path directory\n",
    "        for projid in self.projid_list:  # Iterate over each project ID\n",
    "            file_name = f'{self.document_type_raw}_{projid}_{self.local_time}.txt'  # Generate the file name for the catalog file\n",
    "            if file_name not in file_name_list:  # Check if the file does not already exist\n",
    "                query_url_form = f\"http://search.worldbank.org/api/v2/wds?format=json&proid={projid}&lang_exact=English&docty_exact={self.document_type}&srt=docdt&order=desc\"  # Construct the query URL for the project-based method\n",
    "                try:\n",
    "                    query = requests.get(query_url_form)  # Make a GET request to the query URL\n",
    "                    query_text = query.text  # Get the response text\n",
    "\n",
    "                    if len(query_text) > 1000:  # Check if the response is valid (arbitrary threshold of length > 1000)\n",
    "                        with open(os.path.join(self.category_path, file_name), 'w', encoding='utf-8', errors='ignore') as f:\n",
    "                            f.write(query_text)  # Write the response text to the catalog file\n",
    "                except:\n",
    "                    failed_requests_count += 1  # Increment the counter for failed requests\n",
    "                    print(f'No response ({failed_requests_count} failed requests)')  # Print a failure message with the count\n",
    "                    pass  # Continue to the next iteration if an exception occurs (ignore the exception)\n",
    "   \n",
    "    def download_documents_for_projects(self):\n",
    "        \"\"\"\n",
    "        Download documents using the project-based method.\n",
    "        \"\"\"\n",
    "        print(f'Start downloading the {self.document_type_raw} data from WBG API ...')\n",
    "        t1 = time.time()  # Start time of the download process\n",
    "        file_name_list = os.listdir(self.output_path)  # List of file names in the output path directory\n",
    "        for query_dict, file_name in self.read_catalog_files():  # Iterate over the query dictionaries and file names obtained from read_catalog_files()\n",
    "            projid_match = re.search(r\"(P\\d+)\", file_name, flags=re.S | re.I)  # Search for the project ID pattern in the file name\n",
    "            if projid_match:\n",
    "                projid = projid_match.group(0)  # Extract the project ID from the match object\n",
    "                doc_id_list = [doc_id for doc_id in query_dict.keys() if doc_id.startswith('D')]  # Filter document IDs based on the key starting with 'D'\n",
    "                for doc_id in doc_id_list:  # Iterate over the filtered document IDs\n",
    "                    try:\n",
    "                        date = query_dict.get(doc_id).get('docdt')[:10]  # Extract the date associated with the document ID\n",
    "                        if self.download_version == 'txt':\n",
    "                            file_name = f'{self.document_type_raw}_{projid}_{date}_{doc_id}.txt'  # Construct the file name for text file\n",
    "                        else:\n",
    "                            file_name = f'{self.document_type_raw}_{projid}_{date}_{doc_id}.pdf'  # Construct the file name for PDF file\n",
    "                        if file_name not in file_name_list:  # Check if the file name is not in the list of existing file names\n",
    "                            texturl = query_dict.get(doc_id).get('txturl')  # Get the URL for the text version of the document\n",
    "                            pdfurl = query_dict.get(doc_id).get('pdfurl')  # Get the URL for the PDF version of the document\n",
    "                            try:\n",
    "                                if self.download_version == 'txt':  # Downloading the text version of the document\n",
    "                                    file_query = requests.get(texturl)  # Get the document content from the URL\n",
    "                                    file_text = file_query.text  # Extract the text content from the response\n",
    "                                    with open(os.path.join(self.output_path, file_name), 'w', encoding='utf-8', errors='ignore') as f:  # Open a file in write mode and save the text content\n",
    "                                        f.write(file_text)\n",
    "                                else:  # Downloading the PDF version of the document\n",
    "                                    file_query = requests.get(pdfurl)  # Get the document content from the URL\n",
    "                                    file_text = file_query.content  # Extract the binary content from the response\n",
    "                                    with open(os.path.join(self.output_path, file_name), 'wb') as f:  # Open a file in write binary mode and save the binary content\n",
    "                                        f.write(file_text)\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        print(f'Warning! {doc_id} failed to get docdt')\n",
    "                        pass\n",
    "        t2 = time.time()  # End time of the download process\n",
    "        print('Data downloaded successfully!')\n",
    "        print(f'You can find them in the folder {self.output_path}')\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the bulk download process based on the input parameters.\n",
    "        \"\"\"\n",
    "        if self.projid_list == None:\n",
    "            self.generate_catalog_for_dates()  # Generate catalog files for the date-based method\n",
    "            self.download_documents_for_dates()  # Download documents using the date-based method\n",
    "        else:\n",
    "            self.generate_catalog_for_projects()  # Generate catalog files for the project-based method\n",
    "            self.download_documents_for_projects()  # Download documents using the project-based method\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Call the 'run' method when the instance is called as a function.\n",
    "        \"\"\"\n",
    "        return self.run()\n",
    "\n",
    "    \n",
    "\n",
    "def read_project_ids_from_excel(excel_path, column_name='Proj.Id'):\n",
    "    try:\n",
    "        df = pd.read_excel(excel_path)\n",
    "        return df[column_name].dropna().tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return []\n",
    "\n",
    "def bulk_download_projectID(input_dict):\n",
    "    document_type_list = input_dict.get('document_type')\n",
    "\n",
    "    if document_type_list is None:\n",
    "        print(\"Error: 'file_type' is missing or set to None in the input dictionary.\")\n",
    "        return\n",
    "    for document_type in document_type_list:\n",
    "        if document_type not in document_type_list:\n",
    "            continue\n",
    "        SingleTypeBulkDownload(input_dict, document_type)()\n",
    "        print('-' * 50)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    download_folder_path = '' # Download Folder Path\n",
    "    selected_file_type = [''] # Choose from [\"icrr\", \"icr\", \"ppar\", \"pad\", \"scd\", \"isr\", \"pd\", \"esmp\", \"cas\", \"cpf\", \"cpe\", \"cen\", \"cren\", \"isn\", \"cpe\", \"asa\", \"clrr\", \"pp\"]\n",
    "    download_version = 'txt' # Choose from Either txt or pdf\n",
    "    excel_path = '.xlsx' # Path to the excel file containing the Project Ids to be downloaded\n",
    "    project_ids = read_project_ids_from_excel(excel_path)\n",
    "\n",
    "    input_dict = {\n",
    "        'root_path': download_folder_path,\n",
    "        'document_type': selected_file_type,\n",
    "        'projid_list': project_ids,\n",
    "        'download_version': download_version\n",
    "    }\n",
    "\n",
    "    bulk_download_projectID(input_dict)\n",
    "    \n",
    "    \n",
    "\n",
    "selected_file_type = selected_file_type[0] if isinstance(selected_file_type, list) else selected_file_type\n",
    "\n",
    "# Function to extract project ID from a file name\n",
    "def extract_project_id(file_name):\n",
    "    parts = file_name.split('_')\n",
    "    return parts[1] if len(parts) >= 2 else None\n",
    "\n",
    "# Function to extract project ID and GUID from a JSON file\n",
    "def extract_project_id_and_guid_from_json(json_path):\n",
    "    try:\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            documents = json_data.get(\"documents\", {})\n",
    "            for doc_info in documents.values():\n",
    "                project_id = doc_info.get(\"projectid\")\n",
    "                guid = doc_info.get(\"guid\")\n",
    "                if project_id and guid:\n",
    "                    return project_id, guid\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "# Function to rename files based on project ID and GUID\n",
    "def rename_actual_file(file_path, project_id, guid):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    parts = base_name.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        extension = parts[-1].split('.')[1]\n",
    "        new_file_name = f'{project_id}_{selected_file_type}_{guid}.{extension}'\n",
    "        new_path = os.path.join(os.path.dirname(file_path), new_file_name)\n",
    "        os.rename(file_path, new_path)\n",
    "\n",
    "# Function to rename all files in a folder based on project IDs and GUIDs from a JSON source\n",
    "def rename_actual_files(actual_files_folder, json_files_folder):\n",
    "    # Map project IDs to GUIDs from JSON files\n",
    "    project_id_to_guid = {}\n",
    "    for json_file in os.listdir(json_files_folder):\n",
    "        if json_file.endswith(\".txt\"):\n",
    "            json_path = os.path.join(json_files_folder, json_file)\n",
    "            project_id, guid = extract_project_id_and_guid_from_json(json_path)\n",
    "            if project_id and guid:\n",
    "                project_id_to_guid[project_id] = guid\n",
    "\n",
    "    # Rename files in the folder based on project ID and GUID\n",
    "    for file_name in os.listdir(actual_files_folder):\n",
    "        if file_name.endswith(\".pdf\") or file_name.endswith(\".txt\"):\n",
    "            project_id = extract_project_id(file_name)\n",
    "            if project_id in project_id_to_guid:\n",
    "                guid = project_id_to_guid[project_id]\n",
    "                rename_actual_file(os.path.join(actual_files_folder, file_name), project_id, guid)\n",
    "\n",
    "# Rename files and create Excel summary\n",
    "actual_files_folder = f\"{download_folder_path}/{selected_file_type}_folder\"\n",
    "json_files_folder = f\"{download_folder_path}/{selected_file_type}_category_folder\"\n",
    "\n",
    "rename_actual_files(actual_files_folder, json_files_folder)\n",
    "\n",
    "# Function to create an Excel summary for downloaded files\n",
    "def create_excel_summary(folder_path):\n",
    "    # Initialize the Excel workbook and sheet\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = \"Downloaded Files\"\n",
    "\n",
    "    # Set column headers\n",
    "    sheet[\"A1\"] = \"Proj.Id\"\n",
    "    sheet[\"B1\"] = \"File Type\"\n",
    "\n",
    "    # Populate the Excel sheet with file information\n",
    "    row_num = 2\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if \"_\" in file_name and \".\" in file_name:\n",
    "            parts = file_name.split(\"_\")\n",
    "            project_id = parts[0]\n",
    "            file_type = parts[1]\n",
    "            sheet.cell(row=row_num, column=1, value=project_id)\n",
    "            sheet.cell(row=row_num, column=2, value=file_type)\n",
    "            row_num += 1\n",
    "\n",
    "    # Ensure the folder exists and create it if not\n",
    "    os.makedirs(folder_path, exist_ok=True)  \n",
    "\n",
    "    # Save the Excel workbook in the specified output folder\n",
    "    workbook.save(f\"{download_folder_path}/{selected_file_type}_Downloaded_Project_IDs.xlsx\")\n",
    "\n",
    "# Example folder path for creating the Excel summary\n",
    "\n",
    "# Call the function to create the Excel summary\n",
    "create_excel_summary(f\"{download_folder_path}/{selected_file_type}_folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376924f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
